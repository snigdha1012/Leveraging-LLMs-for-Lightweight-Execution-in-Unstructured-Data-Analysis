{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T02:50:46.676941Z",
     "start_time": "2025-12-06T02:50:11.785191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "RAG-Integrated Language Model Selector\n",
    "- Runs several language-ID models over multilingual samples\n",
    "- Collects accuracy & latency\n",
    "- Builds FAISS vector DB over benchmarks.csv\n",
    "- Retrieves evidence for model selection\n",
    "- Uses Ollama (Qwen) to pick best model based on:\n",
    "    • Highest accuracy\n",
    "    • Or fastest model meeting target accuracy\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Optional libraries\n",
    "try:\n",
    "    import langid\n",
    "    LANGID_AVAILABLE = True\n",
    "except:\n",
    "    LANGID_AVAILABLE = False\n",
    "    print(\"langid.py not installed. Install with: pip install langid\")\n",
    "\n",
    "try:\n",
    "    from ollama import chat\n",
    "    OLLAMA_AVAILABLE = True\n",
    "except:\n",
    "    OLLAMA_AVAILABLE = False\n",
    "    print(\"Ollama not installed. RAG-LM selection disabled.\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Config\n",
    "BENCHMARK_PATH = \"benchmarks_ld.csv\"\n",
    "TOP_K_EVIDENCE = 5\n",
    "\n",
    "LANGUAGE_MODELS = [\n",
    "    \"papluca/xlm-roberta-base-language-detection\",\n",
    "    \"Joshi-Aryan/Fine_Tuned_HF_Language_Identification_Model\",\n",
    "    \"langid.py\"\n",
    "]\n",
    "\n",
    "# Device\n",
    "DEVICE = (\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# Load multilingual samples\n",
    "languages = [\"en\", \"fr\", \"es\", \"de\"]\n",
    "texts, true_labels = [], []\n",
    "\n",
    "for lang in languages:\n",
    "    ds = load_dataset(\"wiki40b\", lang, split=\"train[:25]\")\n",
    "    texts.extend(ds[\"text\"])\n",
    "    true_labels.extend([lang] * len(ds))\n",
    "\n",
    "# Model runners\n",
    "def run_model_hf(model_name, texts):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    for t in texts:\n",
    "        enc = tokenizer(t, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out = model(**enc)\n",
    "        pred_id = out.logits.argmax(dim=1).item()\n",
    "        preds.append(model.config.id2label[pred_id].lower()[:2])\n",
    "    return preds\n",
    "\n",
    "def run_langid_model(texts):\n",
    "    if not LANGID_AVAILABLE:\n",
    "        raise RuntimeError(\"langid.py not installed.\")\n",
    "    return [langid.classify(t)[0] for t in texts]\n",
    "\n",
    "def run_any_model(model_name, texts):\n",
    "    if model_name == \"langid.py\":\n",
    "        return run_langid_model(texts)\n",
    "    return run_model_hf(model_name, texts)\n",
    "\n",
    "# Execute all models\n",
    "def run_batch(texts, true_labels):\n",
    "    results = []\n",
    "    for model in LANGUAGE_MODELS:\n",
    "        try:\n",
    "            print(f\"Running model: {model}\")\n",
    "            start = time.time()\n",
    "            preds = run_any_model(model, texts)\n",
    "            latency = round(time.time() - start, 2)\n",
    "            acc = round(accuracy_score(true_labels, preds) * 100, 2)\n",
    "\n",
    "            print(f\"Acc={acc}% | Latency={latency}s\")\n",
    "            results.append({\n",
    "                \"model\": model,\n",
    "                \"accuracy\": acc,\n",
    "                \"latency\": latency\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED {model}: {e}\")\n",
    "    return results\n",
    "\n",
    "# Build FAISS (RAG)\n",
    "def build_vector_db(path):\n",
    "    df = pd.read_csv(path)\n",
    "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    docs = [\n",
    "        f\"Model: {r['model']} | Dataset: {r['dataset']} | Accuracy: {r['accuracy']} | Latency: {r['latency']} | Notes: {r['notes']}\"\n",
    "        for _, r in df.iterrows()\n",
    "    ]\n",
    "    emb = embedder.encode(docs, show_progress_bar=False)\n",
    "    dim = emb.shape[1]\n",
    "\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(emb, dtype=\"float32\"))\n",
    "    return df, index, embedder, docs\n",
    "\n",
    "def rag_retrieve(query, df, index, embedder, docs, k=TOP_K_EVIDENCE):\n",
    "    q_emb = embedder.encode([query]).astype(\"float32\")\n",
    "    D, I = index.search(q_emb, k)\n",
    "    return \"\\n\".join(docs[i] for i in I[0])\n",
    "\n",
    "# Qwen model selection\n",
    "def qwen_select(results, rag_context, goal, target_acc=None):\n",
    "    if not OLLAMA_AVAILABLE:\n",
    "        print(\"Ollama not available.\")\n",
    "        return None\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are a strict evaluator selecting the best **language identification** model.\n",
    "\n",
    "        Retrieved benchmark evidence:\n",
    "        {rag_context}\n",
    "\n",
    "        Evaluation results on sample data:\n",
    "        {json.dumps(results, indent=2)}\n",
    "\n",
    "        Selection rules:\n",
    "        - If goal=accuracy → choose highest accuracy (tie → lowest latency)\n",
    "        - If goal=latency → choose fastest model with accuracy ≥ {target_acc}\n",
    "        - Output ONLY the model name.\n",
    "    \"\"\"\n",
    "\n",
    "    resp = chat(model=\"qwen2.5:7b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return resp.message.content.strip()\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n1) Most accurate model\")\n",
    "    print(\"2) Fastest model above accuracy threshold\")\n",
    "    choice = input(\"\\nQuery options:\").strip()\n",
    "\n",
    "    results = run_batch(texts, true_labels)\n",
    "\n",
    "    df, index, embedder, docs = build_vector_db(BENCHMARK_PATH)\n",
    "    rag = rag_retrieve(\n",
    "        \"best multilingual language identification model\",\n",
    "        df, index, embedder, docs\n",
    "    )\n",
    "\n",
    "    if choice == \"1\":\n",
    "        selected = qwen_select(results, rag, goal=\"accuracy\")\n",
    "    else:\n",
    "        target = float(input(\"Enter target accuracy: \"))\n",
    "        selected = qwen_select(results, rag, goal=\"latency\", target_acc=target)\n",
    "\n",
    "    print(\"\\n=== SELECTED MODEL ===\")\n",
    "    print(selected)\n"
   ],
   "id": "8503213f70a55a5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "1) Most accurate model\n",
      "2) Fastest model above accuracy threshold\n",
      "Running model: papluca/xlm-roberta-base-language-detection\n",
      "Acc=95.0% | Latency=6.77s\n",
      "Running model: Joshi-Aryan/Fine_Tuned_HF_Language_Identification_Model\n",
      "Acc=50.0% | Latency=6.55s\n",
      "Running model: langid.py\n",
      "Acc=99.0% | Latency=0.05s\n",
      "\n",
      "=== SELECTED MODEL ===\n",
      "Based on the provided evaluation results and selection rules, here is the chosen model:\n",
      "\n",
      "For **accuracy** as the goal:\n",
      "- The highest accuracy among the evaluated models is 99.0%, which is achieved by the `langid.py` model.\n",
      "\n",
      "Therefore, the selected model for the accuracy goal is: **langid.py**\n",
      "\n",
      "For **latency** as the goal:\n",
      "- The fastest model with an accuracy ≥ None (i.e., any non-zero accuracy) is the `papluca/xlm-roberta-base-language-detection` model with a latency of 6.77.\n",
      "\n",
      "Therefore, the selected model for the latency goal is: **papluca/xlm-roberta-base-language-detection**\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
